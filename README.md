# ğŸ”§ Pure Financial Document ETL Pipeline

A **data engineering focused** ETL pipeline that extracts from unstructured financial document data (pdf, spreadsheet, doc) without making analytical assumptions or classifications.

## ğŸ¯ **Pure ETL Philosophy**

This pipeline follows **separation of concerns** principles:

- **ETL Layer**: Extract â†’ Structure â†’ Export (no analysis)

## ğŸš€ **Quick Start**

### **Installation**
```bash
pip install streamlit pandas PyPDF2 openpyxl
```

### **Launch Web Interface**
```bash
streamlit run pure_etl_frontend.py
```

### **Access Application**
Open your browser to: `http://localhost:8502`

## ğŸ“Š **What This ETL Does**

### **âœ… Raw Data Extraction**
- **PDF Documents**: Text extraction from earnings reports
- **Excel Files**: Multi-sheet data extraction
- **Text Files**: Direct text processing
- **Sentence Segmentation**: Clean, structured sentences

### **âœ… Raw Feature Extraction**
- **`all_financial_terms`**: Financial vocabulary found (no classification)
- **`financial_figures`**: Numbers and amounts extracted (no interpretation)
- **`temporal_indicators`**: Time-related language (no actual/projection labels)
- **`speaker_raw`**: Speaker patterns identified (no role classification)

### **âœ… Factual Boolean Flags**
- **`has_financial_terms`**: Terms present or not
- **`has_financial_figures`**: Figures present or not
- **`has_temporal_language`**: Temporal words present or not
- **`has_speaker_identified`**: Speaker pattern found or not

## ğŸš« **What This ETL Does NOT Do**

### **âŒ No Analytical Assumptions**
- No topic classification (Revenue & Growth, Risk Management, etc.)
- No actual vs projection classification
- No financial content relevance scoring
- No speaker role interpretation (CEO, CFO, Analyst)

### **âŒ No Machine Learning**
- No topic modeling
- No sentiment analysis
- No content classification
- No predictive features

## ğŸ“ˆ **Output Schema**

### **Core Fields**
```csv
source_file,institution,quarter,sentence_id,speaker_raw,text,source_type
```

### **Raw Extraction Fields**
```csv
all_financial_terms,financial_figures,financial_figures_text,temporal_indicators
```

### **Factual Flags**
```csv
has_financial_terms,has_financial_figures,has_temporal_language,has_speaker_identified
```

### **Metadata**
```csv
word_count,char_count,processing_date,extraction_timestamp
```

## ğŸ”„ **Example Processing**

### **Input Document**
```
"We reported revenue of $2.5 billion this quarter, up 15% from last year."
```

### **Pure ETL Output**
```csv
all_financial_terms: "revenue"
financial_figures: "$2.5 billion|15%"
temporal_indicators: "reported|this quarter|last year"
has_financial_terms: True
has_financial_figures: True
has_temporal_language: True
```

### **No Analysis Applied**
- âŒ No classification as "actual" vs "projection"
- âŒ No topic assignment like "Revenue & Growth"
- âŒ No sentiment or relevance scoring

## ğŸ—ï¸ **Architecture**

### **Pure ETL Pipeline**
```
Documents â†’ Extract Text â†’ Segment Sentences â†’ Extract Raw Features â†’ Export CSV
```

### **Downstream Analysis (Separate)**
```
Raw CSV â†’ Topic Modeling â†’ Classification â†’ Feature Engineering â†’ ML Models
```

## ğŸ› ï¸ **Technical Features**

### **âœ… Missing Value Handling**
- No null values in output
- Consistent defaults for all fields
- NLP-ready datasets

### **âœ… Multi-Format Support**
- PDF processing with PyPDF2
- Excel processing with openpyxl
- Text file processing
- Graceful error handling

### **âœ… Web Interface**
- Drag-and-drop file upload
- Multi-institution processing
- Progress tracking
- Processing history
- CSV download

## ğŸ“š **Use Cases**

### **Financial Institutions**
- Earnings call transcript processing
- Financial report data extraction
- Regulatory document structuring
- Multi-quarter analysis preparation

### **Research & Analytics**
- Academic financial research
- Market analysis preparation
- NLP model training data
- Time series analysis datasets

### **Compliance & Audit**
- Document processing audit trails
- Structured data for compliance
- Historical document analysis
- Regulatory reporting preparation

## ğŸ”§ **Development**

### **Project Structure**
```
boe-etl/
â”œâ”€â”€ pure_etl_frontend.py    # Main Streamlit application
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .gitignore             # Git ignore patterns
â””â”€â”€ LICENSE                # MIT License
```

### **Dependencies**
- **streamlit**: Web interface framework
- **pandas**: Data manipulation
- **PyPDF2**: PDF text extraction
- **openpyxl**: Excel file processing

## ğŸ“„ **License**

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ¤ **Contributing**

This is a pure ETL pipeline focused on data engineering principles. Contributions should maintain the separation between extraction and analysis.

### **Guidelines**
- Keep ETL layer free of analytical assumptions
- Maintain raw data extraction focus
- Preserve downstream analysis flexibility
- Follow data engineering best practices

## ğŸ¯ **Philosophy: Extract, Don't Analyze**

This pipeline embodies the principle that **ETL should extract and structure data, not make analytical decisions**. Analysis belongs in separate, specialized pipelines that can evolve independently.

**Pure ETL = Maximum Flexibility for Downstream Analysis** ğŸ”§
